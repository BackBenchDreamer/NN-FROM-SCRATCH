
# Neural Network From Scratch

This project implements a simple **Neural Network** from scratch using only **NumPy** (without deep learning frameworks like TensorFlow or PyTorch).  
It is designed as a learning resource to understand the fundamentals of forward propagation, backpropagation, and gradient descent.

## ğŸ“‚ Project Structure
```

NN-FROM-SCRATCH/
â”‚â”€â”€ main.ipynb        # Jupyter Notebook with the implementation
â”‚â”€â”€ README.md         # Project documentation
â”‚â”€â”€ LICENSE           # MIT License

````

## ğŸš€ Features
- Implements a fully connected feedforward neural network
- Forward propagation and backpropagation
- Gradient descent optimization
- Accuracy evaluation
- Modular and beginner-friendly code

## âš¡ Requirements
- Python 3.8+
- NumPy
- Jupyter Notebook (for running `main.ipynb`)

Install dependencies:
```
pip install numpy notebook
````

## â–¶ï¸ Usage

Run the notebook:

```
jupyter notebook main.ipynb
```

## ğŸ“– Learning Goals

This project is meant for **educational purposes**:

* Understand how neural networks work at the mathematical level
* Learn backpropagation and gradient descent
* Build ML intuition without using external libraries

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---
